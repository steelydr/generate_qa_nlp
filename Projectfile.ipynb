{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f07ae53f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\dsoni\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\dsoni\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\dsoni\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\dsoni\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\dsoni\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "from flask import Flask, render_template_string, request\n",
    "import nltk\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.chunk import RegexpParser\n",
    "import random\n",
    "from itertools import chain\n",
    "\n",
    "# Apply the asyncio patch to allow Flask to run inside Jupyter\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Initialize Flask app\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "\n",
    "# Grammar for chunking\n",
    "CHUNK_GRAMMAR = r\"\"\"\n",
    "    CHUNK: {<NN>+<IN|DT>*<NN>+}\n",
    "           {<NN>+<IN|DT>*<NNP>+}\n",
    "           {<NNP>+<NNS>*}\n",
    "\"\"\"\n",
    "chunk_parser = RegexpParser(CHUNK_GRAMMAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba0403ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubjectiveTest:\n",
    "    def __init__(self, data, no_of_ques):\n",
    "        self.data = data\n",
    "        self.no_of_ques = no_of_ques\n",
    "        self.question_pattern = [\n",
    "            \"Explain in detail how \",\n",
    "            \"Describe the significance of \",\n",
    "            \"What are the key aspects of \",\n",
    "            \"Discuss the role of \",\n",
    "            \"Provide an overview of \"\n",
    "        ]\n",
    "\n",
    "    def generate_test(self):\n",
    "        sentences = sent_tokenize(self.data)\n",
    "        question_answer = []\n",
    "        used_keywords = set()\n",
    "\n",
    "        for sentence in sentences:\n",
    "            # Extract meaningful keywords (nouns, proper nouns)\n",
    "            tagged_words = pos_tag(word_tokenize(sentence))\n",
    "            chunks = []\n",
    "            for word, pos in tagged_words:\n",
    "                if pos in {\"NN\", \"NNS\", \"NNP\", \"NNPS\"}:\n",
    "                    chunks.append(word.lower())\n",
    "\n",
    "            # Try generating multiple questions from the same sentence using distinct keywords\n",
    "            for i in range(len(chunks)):\n",
    "                # Stop if we've reached the desired number of questions\n",
    "                if len(question_answer) >= self.no_of_ques:\n",
    "                    break\n",
    "\n",
    "                # Create a keyword phrase using up to 3 consecutive nouns starting at position i\n",
    "                keyword = \" \".join(chunks[i:i+3])\n",
    "                if keyword and keyword not in used_keywords:\n",
    "                    used_keywords.add(keyword)\n",
    "                    pattern = np.random.randint(0, len(self.question_pattern))\n",
    "                    question = self.question_pattern[pattern] + keyword + \"?\"\n",
    "                    question_answer.append({\n",
    "                        \"Question\": question,\n",
    "                        \"Answer\": sentence\n",
    "                    })\n",
    "\n",
    "            # Stop processing more sentences if we've reached required questions\n",
    "            if len(question_answer) >= self.no_of_ques:\n",
    "                break\n",
    "\n",
    "        return question_answer\n",
    "    \n",
    "class ObjectiveTest:\n",
    "    def __init__(self, data, no_of_ques):\n",
    "        self.data = data\n",
    "        self.no_of_ques = no_of_ques\n",
    "        self.used_distractors = set()  # Track all used distractors\n",
    "        # Define chunking pattern for noun phrases\n",
    "        self.chunk_pattern = \"\"\"\n",
    "            CHUNK: {<DT>?<JJ>*<NN.*>+}\n",
    "                   {<NNP>+}\n",
    "                   {<JJ>*<NN.*>}\n",
    "        \"\"\"\n",
    "        self.chunk_parser = RegexpParser(self.chunk_pattern)\n",
    "\n",
    "    def get_wordnet_relationships(self, word):\n",
    "        \"\"\"Get related words using various WordNet relationships\"\"\"\n",
    "        related_words = set()\n",
    "        \n",
    "        # Get all synsets for the word\n",
    "        synsets = wn.synsets(word)\n",
    "        for synset in synsets:\n",
    "            # Add lemmas from the same synset (synonyms)\n",
    "            related_words.update(lemma.name() for lemma in synset.lemmas())\n",
    "            \n",
    "            # Add hypernyms (more general terms)\n",
    "            related_words.update(chain.from_iterable(\n",
    "                lemma.name() for hyper in synset.hypernyms() \n",
    "                for lemma in hyper.lemmas()\n",
    "            ))\n",
    "            \n",
    "            # Add hyponyms (more specific terms)\n",
    "            related_words.update(chain.from_iterable(\n",
    "                lemma.name() for hypo in synset.hyponyms() \n",
    "                for lemma in hypo.lemmas()\n",
    "            ))\n",
    "            \n",
    "            # Add sister terms (share a hypernym)\n",
    "            for hypernym in synset.hypernyms():\n",
    "                for hyponym in hypernym.hyponyms():\n",
    "                    related_words.update(lemma.name() for lemma in hyponym.lemmas())\n",
    "            \n",
    "            # Add meronyms (part-of relationships)\n",
    "            for meronym in synset.part_meronyms():\n",
    "                related_words.update(lemma.name() for lemma in meronym.lemmas())\n",
    "            \n",
    "            # Add holonyms (whole-of relationships)\n",
    "            for holonym in synset.part_holonyms():\n",
    "                related_words.update(lemma.name() for lemma in holonym.lemmas())\n",
    "\n",
    "        return {word.replace('_', ' ') for word in related_words}\n",
    "\n",
    "    def get_smart_distractors(self, phrase, context_sentence):\n",
    "        \"\"\"\n",
    "        Generate unique distractors using multiple strategies\n",
    "        \"\"\"\n",
    "        all_distractors = set()\n",
    "        phrase_lower = phrase.lower()\n",
    "        \n",
    "        # Strategy 1: WordNet relationships for each word in the phrase\n",
    "        words = phrase_lower.split()\n",
    "        for word in words:\n",
    "            related_words = self.get_wordnet_relationships(word)\n",
    "            # Create phrase variations by replacing each word\n",
    "            for related in related_words:\n",
    "                if related.lower() != word:\n",
    "                    new_phrase = phrase.replace(word, related)\n",
    "                    if new_phrase.lower() != phrase_lower:\n",
    "                        all_distractors.add(new_phrase.title())\n",
    "\n",
    "        # Strategy 2: Part-of-Speech based variations\n",
    "        tagged_words = pos_tag(word_tokenize(context_sentence))\n",
    "        similar_pos_phrases = []\n",
    "        target_pos = pos_tag(word_tokenize(phrase))\n",
    "        target_pattern = [tag for _, tag in target_pos]\n",
    "        \n",
    "        # Find phrases with similar POS pattern\n",
    "        i = 0\n",
    "        while i < len(tagged_words) - len(target_pattern) + 1:\n",
    "            current_pattern = [tag for _, tag in tagged_words[i:i+len(target_pattern)]]\n",
    "            if current_pattern == target_pattern:\n",
    "                candidate = ' '.join(word for word, _ in tagged_words[i:i+len(target_pattern)])\n",
    "                if candidate.lower() != phrase_lower:\n",
    "                    similar_pos_phrases.append(candidate)\n",
    "            i += 1\n",
    "\n",
    "        all_distractors.update(similar_pos_phrases)\n",
    "\n",
    "        # Strategy 3: Length-based variations\n",
    "        if len(all_distractors) < 3:\n",
    "            words = phrase.split()\n",
    "            if len(words) > 1:\n",
    "                # Reverse word order\n",
    "                all_distractors.add(' '.join(words[::-1]))\n",
    "                # Rotate words\n",
    "                all_distractors.add(' '.join(words[1:] + [words[0]]))\n",
    "                # Add/remove modifiers\n",
    "                common_modifiers = ['New', 'Advanced', 'Basic', 'Modern']\n",
    "                for modifier in common_modifiers:\n",
    "                    if not phrase.startswith(modifier):\n",
    "                        all_distractors.add(f\"{modifier} {phrase}\")\n",
    "\n",
    "        # Strategy 4: Structural variations\n",
    "        if len(all_distractors) < 3:\n",
    "            # Handle numeric variations if present\n",
    "            if any(char.isdigit() for char in phrase):\n",
    "                numbers = re.findall(r'\\d+', phrase)\n",
    "                for num in numbers:\n",
    "                    num_int = int(num)\n",
    "                    variants = [num_int * 2, num_int + 10, num_int - 5]\n",
    "                    for variant in variants:\n",
    "                        if variant > 0:\n",
    "                            all_distractors.add(phrase.replace(num, str(variant)))\n",
    "\n",
    "        # Remove any distractors that are too similar to the correct answer\n",
    "        all_distractors = {d for d in all_distractors \n",
    "                          if not self._is_too_similar(d.lower(), phrase_lower)}\n",
    "\n",
    "        # Remove previously used distractors\n",
    "        all_distractors = all_distractors - self.used_distractors\n",
    "\n",
    "        # Convert to list and get top 3 most different distractors\n",
    "        distractors = list(all_distractors)\n",
    "        if len(distractors) > 3:\n",
    "            # Sort by difference from correct answer to get most distinct options\n",
    "            distractors.sort(key=lambda x: self._levenshtein_distance(x.lower(), phrase_lower), reverse=True)\n",
    "            distractors = distractors[:3]\n",
    "        \n",
    "        # Add to used distractors\n",
    "        self.used_distractors.update(distractors)\n",
    "\n",
    "        # If we still don't have enough distractors, generate some\n",
    "        while len(distractors) < 3:\n",
    "            new_distractor = self._generate_fallback_distractor(phrase, len(distractors))\n",
    "            if new_distractor not in self.used_distractors:\n",
    "                distractors.append(new_distractor)\n",
    "                self.used_distractors.add(new_distractor)\n",
    "\n",
    "        return distractors\n",
    "\n",
    "    def _is_too_similar(self, str1, str2, threshold=0.8):\n",
    "        \"\"\"Check if two strings are too similar using Levenshtein distance\"\"\"\n",
    "        distance = self._levenshtein_distance(str1, str2)\n",
    "        max_len = max(len(str1), len(str2))\n",
    "        similarity = 1 - (distance / max_len)\n",
    "        return similarity > threshold\n",
    "\n",
    "    def _levenshtein_distance(self, s1, s2):\n",
    "        \"\"\"Calculate the Levenshtein distance between two strings\"\"\"\n",
    "        if len(s1) < len(s2):\n",
    "            return self._levenshtein_distance(s2, s1)\n",
    "        if len(s2) == 0:\n",
    "            return len(s1)\n",
    "        previous_row = range(len(s2) + 1)\n",
    "        for i, c1 in enumerate(s1):\n",
    "            current_row = [i + 1]\n",
    "            for j, c2 in enumerate(s2):\n",
    "                insertions = previous_row[j + 1] + 1\n",
    "                deletions = current_row[j] + 1\n",
    "                substitutions = previous_row[j] + (c1 != c2)\n",
    "                current_row.append(min(insertions, deletions, substitutions))\n",
    "            previous_row = current_row\n",
    "        return previous_row[-1]\n",
    "\n",
    "    def _generate_fallback_distractor(self, phrase, index):\n",
    "        \"\"\"Generate a fallback distractor when other methods don't provide enough options\"\"\"\n",
    "        words = phrase.split()\n",
    "        if len(words) == 1:\n",
    "            # For single words, modify the word structure\n",
    "            modifications = [\n",
    "                phrase + 's' if not phrase.endswith('s') else phrase[:-1],\n",
    "                phrase[::-1].title(),  # Reverse the word\n",
    "                phrase + str(index + 1)  # Add a number\n",
    "            ]\n",
    "            return modifications[index % len(modifications)]\n",
    "        else:\n",
    "            # For phrases, modify the structure\n",
    "            modifications = [\n",
    "                ' '.join(words[::-1]),  # Reverse word order\n",
    "                ' '.join(sorted(words)),  # Alphabetically sort words\n",
    "                ' '.join(words + [str(index + 1)])  # Add a number\n",
    "            ]\n",
    "            return modifications[index % len(modifications)]\n",
    "\n",
    "    def generate_test(self):\n",
    "        sentences = sent_tokenize(self.data)\n",
    "        question_answer = []\n",
    "        used_phrases = set()\n",
    "\n",
    "        for sentence in sentences:\n",
    "            # Continue generating questions until we reach the desired count\n",
    "            if len(question_answer) >= self.no_of_ques:\n",
    "                break\n",
    "\n",
    "            tagged_words = pos_tag(word_tokenize(sentence))\n",
    "            tree = self.chunk_parser.parse(tagged_words)\n",
    "\n",
    "            for subtree in tree.subtrees():\n",
    "                if subtree.label() == \"CHUNK\":\n",
    "                    phrase = \" \".join(word for word, _ in subtree.leaves())\n",
    "                    \n",
    "                    if phrase not in used_phrases and len(phrase.split()) <= 3:\n",
    "                        used_phrases.add(phrase)\n",
    "                        blanks = \"_\" * len(phrase)\n",
    "                        question = re.sub(re.escape(phrase), blanks, sentence, count=1)\n",
    "                        \n",
    "                        # Get smart distractors using the entire sentence for context\n",
    "                        distractors = self.get_smart_distractors(phrase, sentence)\n",
    "                        \n",
    "                        # Combine correct answer and distractors\n",
    "                        options = [phrase] + distractors\n",
    "                        \n",
    "                        # Shuffle options\n",
    "                        random.shuffle(options)\n",
    "                        \n",
    "                        question_answer.append({\n",
    "                            \"Question\": question,\n",
    "                            \"Answer\": phrase,\n",
    "                            \"Options\": options\n",
    "                        })\n",
    "                        \n",
    "                        # Check if we've met the required number of questions after adding one\n",
    "                        if len(question_answer) >= self.no_of_ques:\n",
    "                            break\n",
    "            # Optional: Check again after finishing sentence chunks\n",
    "            if len(question_answer) >= self.no_of_ques:\n",
    "                break\n",
    "\n",
    "        return question_answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9a9da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5001\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [07/Jan/2025 16:17:36] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [07/Jan/2025 16:18:04] \"POST / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [07/Jan/2025 16:18:16] \"POST / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [07/Jan/2025 16:20:06] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [07/Jan/2025 16:20:23] \"POST / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [07/Jan/2025 16:20:36] \"POST / HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "@app.route('/', methods=['GET', 'POST'])\n",
    "def index():\n",
    "    generated_questions = []\n",
    "    input_text = \"\"\n",
    "    no_of_questions = 0\n",
    "    test_type = \"subjective\"\n",
    "\n",
    "    if request.method == 'POST':\n",
    "        input_text = request.form['input_text']\n",
    "        no_of_questions = int(request.form['no_of_questions'])\n",
    "        test_type = request.form['test_type']\n",
    "\n",
    "        if test_type == 'subjective':\n",
    "            test = SubjectiveTest(input_text, no_of_questions)\n",
    "        elif test_type == 'objective':\n",
    "            test = ObjectiveTest(input_text, no_of_questions)\n",
    "        \n",
    "        generated_questions = test.generate_test()\n",
    "\n",
    "    html_template = \"\"\"\n",
    "    <!DOCTYPE html>\n",
    "    <html lang=\"en\">\n",
    "    <head>\n",
    "        <meta charset=\"UTF-8\">\n",
    "        <meta name=\"viewport\" content=\"width=device-width, initial-scale=1, shrink-to-fit=no\">\n",
    "        <title>Q/A Generator</title>\n",
    "        <!-- Bootstrap CSS -->\n",
    "        <link rel=\"stylesheet\" href=\"https://maxcdn.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css\">\n",
    "        <!-- Font Awesome -->\n",
    "        <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css\">\n",
    "        <style>\n",
    "            :root {\n",
    "                --primary-color: #4361ee;\n",
    "                --secondary-color: #3f37c9;\n",
    "            }\n",
    "            \n",
    "            body {\n",
    "                background-color: #f8f9fa;\n",
    "                padding-top: 4.5rem;\n",
    "            }\n",
    "            \n",
    "            .navbar {\n",
    "                background: linear-gradient(135deg, var(--primary-color), var(--secondary-color));\n",
    "                box-shadow: 0 2px 4px rgba(0,0,0,0.1);\n",
    "            }\n",
    "            \n",
    "            .navbar-brand {\n",
    "                font-weight: 600;\n",
    "                display: flex;\n",
    "                align-items: center;\n",
    "            }\n",
    "            \n",
    "            .card {\n",
    "                border: none;\n",
    "                border-radius: 10px;\n",
    "                box-shadow: 0 4px 6px rgba(0,0,0,0.1);\n",
    "                margin-bottom: 1.5rem;\n",
    "                transition: transform 0.2s ease;\n",
    "            }\n",
    "            \n",
    "            .card:hover {\n",
    "                transform: translateY(-2px);\n",
    "            }\n",
    "            \n",
    "            .form-control {\n",
    "                border-radius: 8px;\n",
    "                border: 1px solid #ced4da;\n",
    "                padding: 0.75rem;\n",
    "            }\n",
    "            \n",
    "            .form-control:focus {\n",
    "                border-color: var(--primary-color);\n",
    "                box-shadow: 0 0 0 0.2rem rgba(67, 97, 238, 0.25);\n",
    "            }\n",
    "            \n",
    "            .btn-primary {\n",
    "                background-color: var(--primary-color);\n",
    "                border: none;\n",
    "                border-radius: 8px;\n",
    "                padding: 0.75rem 1.5rem;\n",
    "                font-weight: 600;\n",
    "                transition: all 0.3s ease;\n",
    "            }\n",
    "            \n",
    "            .btn-primary:hover {\n",
    "                background-color: var(--secondary-color);\n",
    "                transform: translateY(-1px);\n",
    "            }\n",
    "            \n",
    "            .question-card {\n",
    "                border-left: 4px solid var(--primary-color);\n",
    "            }\n",
    "            \n",
    "            .options-grid {\n",
    "                display: grid;\n",
    "                grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));\n",
    "                gap: 1rem;\n",
    "                margin-top: 1rem;\n",
    "            }\n",
    "            \n",
    "            .option-item {\n",
    "                background-color: #f8f9fa;\n",
    "                padding: 0.75rem;\n",
    "                border-radius: 8px;\n",
    "                font-weight: 500;\n",
    "            }\n",
    "\n",
    "            .loading {\n",
    "                position: relative;\n",
    "                pointer-events: none;\n",
    "            }\n",
    "            \n",
    "            .loading:after {\n",
    "                content: '';\n",
    "                position: absolute;\n",
    "                width: 16px;\n",
    "                height: 16px;\n",
    "                top: 0;\n",
    "                left: 0;\n",
    "                right: 0;\n",
    "                bottom: 0;\n",
    "                margin: auto;\n",
    "                border: 3px solid #ffffff;\n",
    "                border-top-color: transparent;\n",
    "                border-radius: 50%;\n",
    "                animation: spin 1s ease infinite;\n",
    "            }\n",
    "            \n",
    "            @keyframes spin {\n",
    "                from { transform: rotate(0deg); }\n",
    "                to { transform: rotate(360deg); }\n",
    "            }\n",
    "        </style>\n",
    "    </head>\n",
    "    <body>\n",
    "        <!-- Navigation Bar -->\n",
    "        <nav class=\"navbar navbar-expand-md navbar-dark fixed-top\">\n",
    "            <div class=\"container\">\n",
    "                <a class=\"navbar-brand\" href=\"#\">\n",
    "                    <i class=\"fas fa-brain mr-2\"></i>\n",
    "                    Q/A Generator\n",
    "                </a>\n",
    "            </div>\n",
    "        </nav>\n",
    "\n",
    "        <div class=\"container\">\n",
    "            <div class=\"card mt-4 p-4\">\n",
    "                <h1 class=\"h3 mb-4\">\n",
    "                    <i class=\"fas fa-magic mr-2 text-primary\"></i>\n",
    "                    Generate Your Questions\n",
    "                </h1>\n",
    "                <form method=\"POST\" id=\"questionForm\">\n",
    "                    <div class=\"form-group\">\n",
    "                        <label for=\"input_text\">\n",
    "                            <i class=\"fas fa-file-alt mr-2\"></i>Input Text\n",
    "                        </label>\n",
    "                        <textarea \n",
    "                            class=\"form-control\" \n",
    "                            id=\"input_text\" \n",
    "                            name=\"input_text\" \n",
    "                            rows=\"6\" \n",
    "                            placeholder=\"Paste your text here...\"\n",
    "                            required\n",
    "                        >{{ input_text }}</textarea>\n",
    "                    </div>\n",
    "                    <div class=\"row\">\n",
    "                        <div class=\"col-md-6\">\n",
    "                            <div class=\"form-group\">\n",
    "                                <label for=\"no_of_questions\">\n",
    "                                    <i class=\"fas fa-list-ol mr-2\"></i>Number of Questions\n",
    "                                </label>\n",
    "                                <input \n",
    "                                    type=\"number\" \n",
    "                                    class=\"form-control\" \n",
    "                                    id=\"no_of_questions\" \n",
    "                                    name=\"no_of_questions\" \n",
    "                                    value=\"{{ no_of_questions }}\" \n",
    "                                    min=\"1\" \n",
    "                                    required\n",
    "                                >\n",
    "                            </div>\n",
    "                        </div>\n",
    "                        <div class=\"col-md-6\">\n",
    "                            <div class=\"form-group\">\n",
    "                                <label for=\"test_type\">\n",
    "                                    <i class=\"fas fa-tasks mr-2\"></i>Test Type\n",
    "                                </label>\n",
    "                                <select class=\"form-control\" id=\"test_type\" name=\"test_type\" required>\n",
    "                                    <option value=\"subjective\" {% if test_type == 'subjective' %}selected{% endif %}>\n",
    "                                        Subjective\n",
    "                                    </option>\n",
    "                                    <option value=\"objective\" {% if test_type == 'objective' %}selected{% endif %}>\n",
    "                                        Objective\n",
    "                                    </option>\n",
    "                                </select>\n",
    "                            </div>\n",
    "                        </div>\n",
    "                    </div>\n",
    "                    <button type=\"submit\" class=\"btn btn-primary btn-block\">\n",
    "                        <i class=\"fas fa-wand-magic-sparkles mr-2\"></i>\n",
    "                        Generate Questions\n",
    "                    </button>\n",
    "                </form>\n",
    "            </div>\n",
    "\n",
    "            {% if questions %}\n",
    "                <h2 class=\"h4 mt-5 mb-4\">\n",
    "                    <i class=\"fas fa-clipboard-list mr-2 text-primary\"></i>\n",
    "                    Generated {{ test_type.capitalize() }} Questions\n",
    "                </h2>\n",
    "                <div class=\"questions-container\">\n",
    "                    {% for q in questions %}\n",
    "                        <div class=\"card question-card\">\n",
    "                            <div class=\"card-body\">\n",
    "                                <h5 class=\"card-title text-muted small mb-2\">Question {{ loop.index }}</h5>\n",
    "                                <p class=\"card-text h5 mb-4\">{{ q.Question }}</p>\n",
    "                                {% if test_type == 'objective' %}\n",
    "                                    <h6 class=\"text-muted small mb-2\">Options</h6>\n",
    "                                    <div class=\"options-grid\">\n",
    "                                        {% for option in q.Options %}\n",
    "                                            <div class=\"option-item\">{{ option }}</div>\n",
    "                                        {% endfor %}\n",
    "                                    </div>\n",
    "                                {% endif %}\n",
    "                                <div class=\"mt-4\">\n",
    "                                    <h6 class=\"text-muted small mb-2\">Answer</h6>\n",
    "                                    <p class=\"mb-0\">{{ q.Answer }}</p>\n",
    "                                </div>\n",
    "                            </div>\n",
    "                        </div>\n",
    "                    {% endfor %}\n",
    "                </div>\n",
    "            {% endif %}\n",
    "        </div>\n",
    "\n",
    "        <!-- Bootstrap JS, Popper.js, and jQuery -->\n",
    "        <script src=\"https://code.jquery.com/jquery-3.5.1.slim.min.js\"></script>\n",
    "        <script src=\"https://cdn.jsdelivr.net/npm/popper.js@1.16.1/dist/umd/popper.min.js\"></script>\n",
    "        <script src=\"https://maxcdn.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js\"></script>\n",
    "        <script>\n",
    "            // Add loading state to form submission\n",
    "            document.getElementById('questionForm').addEventListener('submit', function(e) {\n",
    "                const button = this.querySelector('button[type=\"submit\"]');\n",
    "                const icon = button.querySelector('i');\n",
    "                const text = button.textContent.trim();\n",
    "                \n",
    "                button.classList.add('loading');\n",
    "                button.innerHTML = '<span style=\"opacity: 0;\">Generating...</span>';\n",
    "                \n",
    "                // Re-enable after 100ms if form is invalid\n",
    "                setTimeout(() => {\n",
    "                    if (!this.checkValidity()) {\n",
    "                        button.classList.remove('loading');\n",
    "                        button.innerHTML = `<i class=\"${icon.className}\"></i> ${text}`;\n",
    "                    }\n",
    "                }, 100);\n",
    "            });\n",
    "        </script>\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "    return render_template_string(html_template, questions=generated_questions, input_text=input_text, no_of_questions=no_of_questions, test_type=test_type)\n",
    "\n",
    "# Run Flask application\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True, use_reloader=False, port=5001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372a8709",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
